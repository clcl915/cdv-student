## Reading 1 - I Data You, You Data Me (We All Data Together) 

### Part 1
The 5 first words that come to you mind when you hear “data”. Also write down five words that come to your mind when you hear “mouse”. 

**DATA**

|numbers|statistics|graphs/charts|scientists|info|
|-|-|-|-|-|

**MOUSE**

|animal | small | press | keyboard | hand |
|-|-|-|-|-|

### Part 2
**💡 In your own words, briefly trace the “journey” the word “data” made throughout time. Which words do you think might be its neighbors in the future? Why do you think so?**

Data was a “thing of God.” It was derived from a Latin word that meant something “given”.  But since the 20th century and the era of computers, data’s meaning turned from a thing from God to information on the computer as bits and bytes. I remember that in this article, the author describes data as a thing derived from God but raised by computers. I think the word data is evolving into new states as time goes by. In recent years, the word “big data” is all the buzz for news outlets. If we were to look into the future, data’s neighbors might evolve to consist of words like: ethics, equality, inequality, machine learning, robots, artificial intelligence, efficient, simplification, safe, security, opportunity, etc. 

**💡 Describe data “bias” in your own words. Can you think of an example that is not mentioned in the text? How is this bias coming into existence? Try to combine this with your understanding of the claim that “data is reductive”.** 

Data bias is when data is influenced by human culture. In the article, there was a ml model called word2vec that essentially outputted a word’s neighbor based on connections and existing relations. The article highlighted the gender and race bias that the word2vec model had. One example in the article was when it connected woman and nurse with doctor and man. 
Another example that is in NYC there are schools that are academically screened. Based on a student’s test results, attendance, grades, interviews, and other data collected from students, admission to certain middle schools and high schools are offered. These admission screenings have received a ton of backlash of having biases on racial communities in New York. These admission screenings have a huge disadvantage to the Black and Hispanic student communities. Another example is using user generated content. Facebook posts, Twitter tweets, reviews on Yelp and Amazon only represent the opinions of a certain amount of the population that choose to generate this content, but not all of the population. 

This data bias comes from mirroring biases that already exist in our culture today. These biases are seen everyday by just living life and noticing the surrounding events. These data biases don’t capture the entire image. The claim that “data is reductive” is interesting because with data biases, data is a simplified information but disregarding important details and events that exist. It’s conclusion is “reductive” because it doesn’t fully represent the study or population. 